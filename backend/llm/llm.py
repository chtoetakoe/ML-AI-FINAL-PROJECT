import json
import requests
from domain import DOMAIN_CONTEXT


def call_ollama(prompt: str, model="llama3:8b", temperature=0.1):
    """Call Ollama API locally with improved error handling"""
    try:
        # First check if ollama is running
        health_response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if health_response.status_code != 200:
            return "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: Ollama áƒ¡áƒ”áƒ áƒ•áƒ˜áƒ¡áƒ˜ áƒáƒ  áƒ›áƒ£áƒ¨áƒáƒáƒ‘áƒ¡. áƒ’áƒ—áƒ®áƒáƒ•áƒ— áƒ“áƒáƒ§áƒ”áƒœáƒáƒ— ollama serve"
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "system": "You are a Georgian statistical assistant.",
                "temperature": temperature,
                "stream": False,
                "options": {
                    "timeout": 300,
                    "num_ctx": 2048,
                    "num_predict": 512,
                }
            },
            timeout=300
        )

        if response.status_code == 200:
            result = response.json()
            return result.get("response", "").strip()
        else:
            return f"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ ollama-áƒ¡ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ˜áƒ¡áƒáƒ¡: {response.status_code} - {response.text}"
            
    except requests.exceptions.Timeout:
        return "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: Ollama-áƒ¡ áƒáƒáƒ¡áƒ£áƒ®áƒ˜áƒ¡ áƒšáƒáƒ“áƒ˜áƒœáƒ˜áƒ¡ áƒ“áƒ áƒ áƒáƒ›áƒáƒ˜áƒ¬áƒ£áƒ áƒ. áƒ¡áƒªáƒáƒ“áƒ”áƒ— áƒ£áƒ¤áƒ áƒ áƒ›áƒáƒ™áƒšáƒ” áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ˜áƒ—."
    except requests.exceptions.ConnectionError:
        return "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: Ollama-áƒ¡áƒ—áƒáƒœ áƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ˜ áƒ•áƒ”áƒ  áƒ“áƒáƒ›áƒ§áƒáƒ áƒ“áƒ. áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ— áƒ áƒáƒ› ollama serve áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ."
    except requests.exceptions.RequestException as e:
        return f"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ ollama-áƒ¡áƒ—áƒáƒœ áƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ˜áƒ¡áƒáƒ¡: {str(e)}"


def query_handler(data, path):
    """Navigate through the data structure following the given path"""
    for category in data:
        if category.get("name") == path[0]:
            return category
    return []


def extract_tables_and_charts(data):
    """Recursively walk the data to collect all tables and charts"""
    tables = []
    charts = []

    def walk(node):
        if isinstance(node, dict):
            if node.get("type") == "table":
                tables.append(node.get("data", []))
            elif node.get("type") == "chart":
                charts.append(node.get("data", []))

            for key, value in node.items():
                if key == "data" and isinstance(value, list):
                    for item in value:
                        walk(item)
        elif isinstance(node, list):
            for item in node:
                walk(item)

    walk(data)
    return tables, charts


def filter_tables_by_query(tables, query):
    """Filter only the tables that contain query keywords"""
    query = query.lower()
    return [
        table for table in tables
        if any(
            any(query in str(value).lower() for value in row.values())
            for row in table
        )
    ]


def llm_full_pipeline(user_query: str, raw_data, llm=call_ollama):
    """Full pipeline: map â†’ retrieve â†’ analyze with improved error handling"""
    if isinstance(raw_data, str):
        try:
            data = json.loads(raw_data)
        except json.JSONDecodeError:
            return {
                "title": "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ˜áƒ¡áƒáƒ¡",
                "raw_table": [],
                "analysis": "áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ JSON áƒ¤áƒáƒ áƒ›áƒáƒ¢áƒ¨áƒ˜ áƒ’áƒáƒ áƒ“áƒáƒ¥áƒ›áƒœáƒ áƒ•áƒ”áƒ  áƒ›áƒáƒ®áƒ”áƒ áƒ®áƒ“áƒ."
            }
    else:
        data = raw_data

    valid_domains = list(DOMAIN_CONTEXT.keys())

    domain_prompt = f"""You are an expert assistant working with statistical categories.

Question: "{user_query}"

Available domains: {', '.join(valid_domains)}

Your task: Identify only the relevant domains that can answer this question. 
Return the domain names separated by "__" without any extra explanation."""

    print("ğŸ” áƒ•áƒ˜áƒ«áƒ”áƒ‘ áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡ áƒ—áƒ”áƒ›áƒáƒ¢áƒ˜áƒ™áƒáƒ¡...")
    domain_response = llm(domain_prompt).strip().lower().strip('"')

    if "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ" in domain_response or "error" in domain_response:
        return {
            "title": "áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ AI áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒáƒ¨áƒ˜",
            "raw_table": [],
            "analysis": domain_response
        }

    response_parts = [part.strip() for part in domain_response.split("__")]
    matched_domain = []

    for domain in valid_domains:
        if domain.lower() in domain_response or any(word in domain.lower() for word in response_parts):
            matched_domain.append(domain)

    if not matched_domain:
        for domain in valid_domains:
            for part in response_parts:
                if part in domain.lower() or domain.lower() in part:
                    matched_domain.append(domain)
                    break

    if not matched_domain:
        return {
            "title": "áƒ“áƒáƒ›áƒ”áƒœáƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ",
            "raw_table": [],
            "analysis": f"áƒ¨áƒ”áƒœáƒ˜ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ•áƒ”áƒ  áƒ“áƒáƒ•áƒáƒ™áƒáƒ•áƒ¨áƒ˜áƒ áƒ” áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡ áƒ“áƒáƒ›áƒ”áƒœáƒ—áƒáƒœ. áƒ¡áƒªáƒáƒ“áƒ” áƒ£áƒ¤áƒ áƒ áƒ™áƒáƒœáƒ™áƒ áƒ”áƒ¢áƒ£áƒšáƒ˜ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ. AI áƒáƒáƒ¡áƒ£áƒ®áƒ˜ áƒ˜áƒ§áƒ: {domain_response}"
        }

    print(f"âœ… áƒœáƒáƒáƒáƒ•áƒœáƒ˜áƒ áƒ—áƒ”áƒ›áƒáƒ¢áƒ˜áƒ™áƒ: {', '.join(matched_domain)}")

    all_tables, all_charts = [], []
    for domain in matched_domain:
        path = DOMAIN_CONTEXT[domain]["path"]
        raw_result = query_handler(data, path)
        tables, charts = extract_tables_and_charts(raw_result)
        filtered_tables = filter_tables_by_query(tables, user_query)
        all_tables.extend(filtered_tables)
        all_charts.extend(charts)

    if not all_tables and not all_charts:
        return {
            "title": f"{', '.join(matched_domain)} - áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ",
            "raw_table": [],
            "analysis": "áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡áƒ˜ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. áƒ¨áƒ”áƒ¡áƒáƒ«áƒšáƒáƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒ‘áƒáƒ–áƒ áƒáƒ áƒáƒ¡áƒ áƒ£áƒšáƒ˜áƒ áƒáƒœ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒáƒ áƒáƒ¡áƒ¬áƒáƒ áƒáƒ“ áƒáƒ áƒ˜áƒ¡ áƒ¤áƒáƒ áƒ›áƒ£áƒšáƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜."
        }

    print(f"ğŸ“Š áƒœáƒáƒáƒáƒ•áƒœáƒ˜áƒ: {len(all_tables)} áƒªáƒ®áƒ áƒ˜áƒšáƒ˜, {len(all_charts)} áƒ“áƒ˜áƒáƒ’áƒ áƒáƒ›áƒ")

    limited_table = all_tables
    limited_charts = all_charts[:1] if all_charts else []

    analysis_prompt = f"""Question: "{user_query}"

Data:
{json.dumps(limited_table, ensure_ascii=False, indent=1)}...

Provide a clear, concise analysis based only on the relevant data."""

    print("ğŸ§  áƒ•áƒáƒœáƒáƒšáƒ˜áƒ–áƒ”áƒ‘ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ¡...")
    analysis = llm(analysis_prompt)

    return {
        "title": f"{', '.join(matched_domain)} - áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ˜",
        "raw_table": all_tables,
        "raw_charts": all_charts,
        "analysis": analysis.strip()
    }
